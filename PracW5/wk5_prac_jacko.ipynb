{"cells":[{"cell_type":"markdown","metadata":{"id":"66BqoDAfkz71"},"source":["By Jack O'Brien\n","\n","# Q1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs5nRr9tkz75","executionInfo":{"status":"error","timestamp":1679358665292,"user_tz":-600,"elapsed":1791,"user":{"displayName":"Humphrey Munn","userId":"00554135477618805104"}},"outputId":"ebdcb53f-4f47-4558-ca30-bb2412932fd8","colab":{"base_uri":"https://localhost:8080/","height":380}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-81f87cc19b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w3classif.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'w3classif.csv'"]}],"source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset\n","data = pd.read_csv(\"w3classif.csv\", names=[\"X1\", \"X2\", \"Y\"])\n","\n","\n","def train_test(data, test_size):\n","    # Split into features and target\n","    X = data.drop(\"Y\", axis=1)\n","    y = data[\"Y\"]\n","    \n","    # Split into 70:30 train-test split. This function also shuffles.\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n","    \n","    # Create the decision tree classifier\n","    clf = DecisionTreeClassifier(max_depth=3, random_state=i)\n","    \n","    # Fit the model on the training data\n","    clf.fit(X_train, y_train)\n","    \n","    # Make predictions on the training and test data\n","    y_pred_train = clf.predict(X_train)\n","    y_pred_test = clf.predict(X_test)\n","    \n","    # Calculate the training and test loss\n","    train_loss = 1 - accuracy_score(y_train, y_pred_train)\n","    test_loss = 1 - accuracy_score(y_test, y_pred_test)\n","\n","    return (X_train, y_train), (X_test, y_test), train_loss, test_loss\n","    \n","\n","def train_test_m_times(data, m, test_size=0.3):\n","    # Create empty lists to store the results\n","    train_sets = []\n","    test_sets = []\n","    train_losses = []\n","    test_losses = []\n","\n","    for i in range(m):\n","        train, test, train_loss, test_loss = train_test(data, test_size)\n","        \n","        # Append the results to the lists\n","        train_sets.append(train)\n","        test_sets.append(test)\n","        train_losses.append(train_loss)\n","        test_losses.append(test_loss)\n","\n","    return train_sets, test_sets, train_losses, test_losses\n","\n","\n","train_sets, test_sets, train_losses, test_losses = train_test_m_times(data, 10)"]},{"cell_type":"markdown","metadata":{"id":"stWYWCXVkz77"},"source":["# Q2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcTP83clkz78","outputId":"79b8bc50-63d8-4369-a115-76c8dbdb00f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Losses: [0.025000000000000022, 0.025000000000000022, 0.02857142857142858, 0.042857142857142816, 0.03214285714285714, 0.02857142857142858, 0.021428571428571463, 0.017857142857142905, 0.03214285714285714, 0.0357142857142857]\n","Train loss avg = 0.028928571428571435\n","Test Losses: [0.050000000000000044, 0.07499999999999996, 0.06666666666666665, 0.04166666666666663, 0.025000000000000022, 0.01666666666666672, 0.06666666666666665, 0.05833333333333335, 0.06666666666666665, 0.025000000000000022]\n","Test loss avg = 0.04916666666666667\n"]}],"source":["import numpy as np\n","\n","def print_losses(train_losses, test_losses): \n","    print(\"Train Losses:\", train_losses)\n","    print(\"Train loss avg =\", np.mean(train_losses))\n","    print(\"Test Losses:\", test_losses)\n","    print(\"Test loss avg =\", np.mean(test_losses))\n","\n","print_losses(train_losses, test_losses)"]},{"cell_type":"markdown","metadata":{"id":"bdUe0sMZkz79"},"source":["# Q3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3B0G2MKkz79","outputId":"58f99669-2e48-4a6a-8cc5-39acf0b688ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Losses: [0.036111111111111094, 0.047222222222222276, 0.036111111111111094, 0.03888888888888886, 0.03888888888888886, 0.03888888888888886, 0.030555555555555558, 0.04166666666666663, 0.033333333333333326, 0.04166666666666663]\n","Train loss avg = 0.038333333333333316\n","Test Losses: [0.09999999999999998, 0.0, 0.09999999999999998, 0.025000000000000022, 0.025000000000000022, 0.07499999999999996, 0.025000000000000022, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044]\n","Test loss avg = 0.05000000000000001\n","~~~~\n","Train Losses: [0.020000000000000018, 0.015000000000000013, 0.015000000000000013, 0.010000000000000009, 0.010000000000000009, 0.025000000000000022, 0.020000000000000018, 0.020000000000000018, 0.040000000000000036, 0.030000000000000027]\n","Train loss avg = 0.020500000000000018\n","Test Losses: [0.06999999999999995, 0.06499999999999995, 0.050000000000000044, 0.08999999999999997, 0.06499999999999995, 0.06499999999999995, 0.06499999999999995, 0.06000000000000005, 0.06499999999999995, 0.05500000000000005]\n","Test loss avg = 0.06499999999999997\n"]}],"source":["# First do 90:10 split\n","train_sets, test_sets, train_losses_90, test_losses_90 = train_test_m_times(data, 10, test_size=0.1)\n","print_losses(train_losses_90, test_losses_90)\n","\n","print(\"~~~~\")\n","\n","# Now do 50:50\n","train_sets, test_sets, train_losses_50, test_losses_50 = train_test_m_times(data, 10, test_size=0.5)\n","print_losses(train_losses_50, test_losses_50)"]},{"cell_type":"markdown","metadata":{"id":"fOyVaHzZkz79"},"source":["# Q4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pei99JPgkz7-","outputId":"cd155f7e-d8c7-4105-b50c-abe2535b11bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unbiased standard deviation of train_losses_50: 0.009264628073124873\n","Unbiased standard deviation of test_losses_50: 0.010540925533894572\n","Unbiased standard deviation of train_losses_90: 0.00468485579284205\n","Unbiased standard deviation of test_losses_90: 0.03333333333333332\n"]}],"source":["# Print the unbiased standard deviation of each array\n","print(\"Unbiased standard deviation of train_losses_50:\", np.std(train_losses_50, ddof=1))\n","print(\"Unbiased standard deviation of test_losses_50:\", np.std(test_losses_50, ddof=1))\n","print(\"Unbiased standard deviation of train_losses_90:\", np.std(train_losses_90, ddof=1))\n","print(\"Unbiased standard deviation of test_losses_90:\", np.std(test_losses_90, ddof=1))"]},{"cell_type":"markdown","metadata":{"id":"oPgZtEyUkz7-"},"source":["So, we are trading off between training loss variance and testing loss variance here."]},{"cell_type":"markdown","metadata":{"id":"-irlWPtDkz7_"},"source":["# Q5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbCYvcFQkz7_","outputId":"f295f0eb-fbc3-4611-ccac-f90da3be1de7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean cross-validation error: 0.0600\n","Standard deviation of cross-validation error: 0.0293\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","\n","# Split the data into X and y\n","X = data.iloc[:, :-1]\n","y = data.iloc[:, -1]\n","\n","# Create a decision tree classifier\n","dtc = DecisionTreeClassifier(max_depth=3)\n","\n","# Perform 10-fold cross validation\n","scores = cross_val_score(dtc, X, y, cv=10)\n","\n","# Calculate the mean and standard deviation of the cross-validation error\n","mean_error = 1 - np.mean(scores)\n","std_error = np.std(1 - scores, ddof=1)\n","\n","print(f\"Mean cross-validation error: {mean_error:.4f}\")\n","print(f\"Standard deviation of cross-validation error: {std_error:.4f}\")"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}